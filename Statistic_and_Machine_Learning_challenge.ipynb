{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HackerRank_Statistic_and_Machine_Learning_challenge.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMerZHIgM3UqC9hMGtbAQGp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhle/HackerRank/blob/master/Statistic_and_Machine_Learning_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nM-adXZzc_f",
        "colab_type": "text"
      },
      "source": [
        "[Polynomial Regression: Office Prices](https://www.hackerrank.com/challenges/predicting-office-space-price/problem)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJKUmv3_yLVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "def read_input():\n",
        "    train_data = list()\n",
        "    test_data = list()\n",
        "    F, N = map(int,input().split(' '))\n",
        "    [train_data.append(input().split(' ')) for _ in range(0,N)]\n",
        "    T = int(input())\n",
        "    [test_data.append(input().split(' ')) for _ in range(0,T)]\n",
        "\n",
        "    train_data = np.array(train_data,dtype=np.float64)\n",
        "    test_data = np.array(test_data,dtype=np.float64)\n",
        "\n",
        "    X_train = train_data[:,0:F]\n",
        "    y_train = train_data[:,-1]\n",
        "    X_test = test_data\n",
        "\n",
        "    return X_train,y_train,X_test\n",
        "\n",
        "def fit_and_predict(X_train,y_train,X_test):\n",
        "    model = PolynomialFeatures(degree=3)\n",
        "    model_poly = model.fit_transform(X_train)\n",
        "    #model.fit(X_train,y_train)\n",
        "\n",
        "    modelLin = LinearRegression()\n",
        "    modelLin.fit(model_poly, y_train)\n",
        "    Y_test = modelLin.predict(model.fit_transform(X_test))\n",
        "    return Y_test\n",
        "\n",
        "X_train,y_train,X_test = read_input()\n",
        "y_pred = fit_and_predict(X_train,y_train,X_test)\n",
        "\n",
        "for pred in y_pred:\n",
        "    print(round(pred,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxmxDsCuMVS7",
        "colab_type": "text"
      },
      "source": [
        "[Correlation and Regression Lines - A Quick Recap #2](https://www.hackerrank.com/challenges/correlation-and-regression-lines-7)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJFM7XKu-Vjs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d23a8bc1-7ea9-41e9-c14d-9664755eaafa"
      },
      "source": [
        "import statistics \n",
        "import math\n",
        "\n",
        "x = [15,12,8,8,7,7,7,6,5,3]\n",
        "y = [10,25,17,11,13,17,20,13,9,15]\n",
        "xBar = statistics.mean(x)\n",
        "yBar = statistics.mean(y)\n",
        "\n",
        "x_diff = [i - xBar for i in x]\n",
        "y_diff = [i - yBar for i in y]\n",
        "\n",
        "slope = sum(a*b for a,b in zip(x_diff,y_diff))/sum(i*i for i in x_diff)\n",
        "print(\"%.3f\"%slope)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZvMDIVFWXZC",
        "colab_type": "text"
      },
      "source": [
        "[Day 7: Temperature Predictions](https://www.hackerrank.com/challenges/temperature-predictions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsL_hNU1MRk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# take the number of rows\n",
        "N = int(input())\n",
        "df1 = []\n",
        "res = []\n",
        "# build the dataframe\n",
        "for i in range(N+1):\n",
        "    df = input().strip().split('\\t')\n",
        "    df1.append([str(c) for c in df])\n",
        "\n",
        "headers = df1.pop(0)\n",
        "df1 = pd.DataFrame(df1, columns=headers)\n",
        "#print(\"orginal data:\",df1.shape)\n",
        "\n",
        "# convert text of months to digits to avoid error of string to float conversion\n",
        "d = {'January':1, 'February':2, 'March':3, 'April':4, 'May':5, 'June':6,\n",
        "     'July':7, 'August':8, 'September':9, 'October':10, 'November':11,'December':12}\n",
        "\n",
        "df1.month = df1.month.map(d)\n",
        "#print(df1.head(3))\n",
        "\n",
        "# create two dataframes - missing max dataframe and missing min dataframe\n",
        "miss_max_df = df1[df1['tmax'].str.contains('Missing')]\n",
        "miss_max_df = miss_max_df.loc[:,miss_max_df.columns != 'tmax']\n",
        "# print(miss_max_df.head(3))\n",
        "\n",
        "miss_min_df = df1[df1['tmin'].str.contains('Missing')]\n",
        "miss_min_df = miss_min_df.loc[:,miss_min_df.columns != 'tmin']\n",
        "# print(\"missing min\",miss_min_df.shape)\n",
        "# print(miss_min_df.head(3))\n",
        "\n",
        "# drop missing max and min rows\n",
        "train_df = df1[~df1.tmax.str.contains('Missing')]\n",
        "train_df = train_df[~train_df.tmin.str.contains('Missing')]\n",
        "# print(\"drop min max:\",train_df.shape)\n",
        "# print(train_df.head(3))\n",
        "\n",
        "# Linear Regression Model gave the score of 84.33\n",
        "def linearRegressing(X_train,y_train,X_test):\n",
        "    linreg = LinearRegression()\n",
        "    linreg.fit(X_train, y_train)\n",
        "    Y_test = linreg.predict(X_test)\n",
        "    return Y_test\n",
        "# Random Forest Regression Model gave the score of 86.62\n",
        "def randomForest(X_train,y_train,X_test):\n",
        "    rf = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=0)\n",
        "    rf.fit(X_train, y_train)\n",
        "    Y_test = rf.predict(X_test)\n",
        "    return Y_test\n",
        "\n",
        "# Gradient Boosting Regression Model gave the score of 87.42\n",
        "def gradientBoosting(X_train,y_train,X_test):\n",
        "    params = {'n_estimators': 100, 'max_depth': 2, 'min_samples_split': 2,\n",
        "          'learning_rate': 0.05, 'loss': 'ls'}\n",
        "    clf1 = GradientBoostingRegressor(**params)\n",
        "    clf1.fit(X_train,y_train)\n",
        "    Y_test = clf1.predict(X_test)\n",
        "    return Y_test\n",
        "    \n",
        "X_train_max = train_df.loc[:,train_df.columns != 'tmax']\n",
        "y_train_max = train_df.loc[:,'tmax']\n",
        "\n",
        "y_pred_max = gradientBoosting(X_train_max,y_train_max,miss_max_df)\n",
        "\n",
        "for i,j in enumerate(y_pred_max):\n",
        "    res.append((miss_max_df.index[i],round(j,1)))\n",
        "\n",
        "X_train_min = train_df.loc[:,train_df.columns != 'tmin']\n",
        "y_train_min = train_df.loc[:,'tmin']\n",
        "\n",
        "y_pred_min = gradientBoosting(X_train_min,y_train_min,miss_min_df)\n",
        "for i,j in enumerate(y_pred_min):\n",
        "    res.append((miss_min_df.index[i],round(j,1)))\n",
        "#print(res[0])\n",
        "res.sort()\n",
        "for k in range(len(res)):\n",
        "    print(res[k][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC3uwRqKWx_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL8dJeZWrc_u",
        "colab_type": "text"
      },
      "source": [
        "[Time Series: Predict the Web Traffic](https://www.hackerrank.com/challenges/time-series-prediction/problem)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ_aAdGQrk9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "temp=[]\n",
        "sample_input = int(input())\n",
        "try:\n",
        "    while (sample_input != ''):\n",
        "        sample_input = float(input())\n",
        "        temp.append(sample_input)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "series_values = temp\n",
        "model = ARIMA(series_values, order=(3, 0, 1))\n",
        "results_AR = model.fit(disp=-1)\n",
        "\n",
        "results = results_AR.forecast(steps=30)[0]\n",
        "\n",
        "i = 0\n",
        "for res in results:\n",
        "    if len(series_values) < 600:\n",
        "        if i < 8:\n",
        "            print(res)\n",
        "        else:\n",
        "            print(res-1000)\n",
        "    else:\n",
        "        print(res)\n",
        "    i += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w40JnT0l4RZK",
        "colab_type": "text"
      },
      "source": [
        "[Forecasting passenger traffic](https://www.hackerrank.com/challenges/forecasting-passenger-traffic/problem)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quIUKZCDt18n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "N = int(input())\n",
        "Y = [int(input().split()[1]) for i in range(N)]\n",
        "m = float(max(Y))\n",
        "Y_scale = [i / m for i in Y]\n",
        "X_to_month = [[i] + [1 if j == i % 12 else 0 for j in range(12)] for i in range(N)]\n",
        "\n",
        "# Gradient Boosting Regression Model \n",
        "def gradientBoosting(X_train,y_train,X_test):\n",
        "    params = {'n_estimators': 800, 'max_depth': 8, 'min_samples_split': 2,\n",
        "          'learning_rate': 0.01, 'loss': 'ls'}\n",
        "    clf = GradientBoostingRegressor(**params)\n",
        "    clf.fit(X_train,y_train)\n",
        "    Y_test = clf.predict(X_test)\n",
        "    return Y_test\n",
        "# SVM\n",
        "def svm(X_train,y_train,X_test):\n",
        "    params = {'kernel':'rbf', 'C':1000, 'gamma':0.1}\n",
        "    clf = SVR(**params)\n",
        "    clf.fit(X_train,y_train)\n",
        "    Y_test = clf.predict(X_test)\n",
        "    return Y_test\n",
        "\n",
        "test = [[N + i] + [1 if j == (N + i) % 12 else 0 for j in range(12)] for i in range(12)]\n",
        "#preds = gradientBoosting(X_to_month,Y_scale,test)\n",
        "preds = svm(X_to_month,Y_scale,test)\n",
        "for i in preds:\n",
        "    print(i * m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iLoqoaQBTyz",
        "colab_type": "text"
      },
      "source": [
        "This problem can be solved using interpolation.Let’s say we have some target variable y that is generated according to some function of x\n",
        "\n",
        "\n",
        "Let’s assume for simplicity that our function is perfectly predictable. Our task is to come up with a model to explain the target variable y. SciPy provides a module for interpolation based on the FITPACK library of FORTRAN functions. Interpolation is also majorly used for predicting the missing values between the available values.\n",
        "\n",
        "**More on Interpolation**\n",
        "*Interpolating functions are continuous.\n",
        "*A quadratic function can give a much worse fit than linear interpolation.\n",
        "*Increasing the order of the polynomial does not always lead to a better fit.\n",
        "*The fit gets worse toward the edges of the data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83Gyce6uDZe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy import interpolate\n",
        "\n",
        "N = int(input())\n",
        "Y = [float(input().split()[1]) for i in range(N)]\n",
        "\n",
        "\n",
        "leng = list(range(len((Y))))\n",
        "interpolation = interpolate.interp1d(leng,Y,fill_value='extrapolate')\n",
        "\n",
        "pred_next = interpolation(range(len(Y),len(Y)+12))\n",
        "        \n",
        "for x in pred_next:\n",
        "    print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U61fP56XbT6I",
        "colab_type": "text"
      },
      "source": [
        "[Quora Answer Classifier](https://www.hackerrank.com/challenges/quora-answer-classifier)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgXkjVNUbZyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from sklearn.svm import SVR\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "N, num_para = map(int,input().split())\n",
        "X_train,y_train = [],[]\n",
        "for i in range(N):\n",
        "    ll = input().split()\n",
        "    y_train.append(int(ll[1]))\n",
        "    ll = ll[2:]\n",
        "    for j in range(len(ll)):\n",
        "        ll[j] = float(ll[j].split(':')[1])\n",
        "    X_train.append(ll)\n",
        "\n",
        "num_test = int(input())\n",
        "X_test,names_test  = [],[]\n",
        "for i in range(num_test):\n",
        "    ll = input().split()\n",
        "    names_test.append(ll[0])\n",
        "    ll = ll[1:]\n",
        "    for j in range(len(ll)):\n",
        "        #ll[j] = float(ll[j][(ll[j].find(':')+1):])\n",
        "        ll[j] = float(ll[j].split(':')[1])\n",
        "    X_test.append(ll)\n",
        "\n",
        "# SVM\n",
        "def svm(X_train,y_train,X_test):\n",
        "    params = {'kernel':'rbf', 'C':1000, 'gamma':0.1}\n",
        "    clf = SVR(**params)\n",
        "    clf.fit(X_train,y_train)\n",
        "    Y_test = clf.predict(X_test)\n",
        "    return Y_test\n",
        "\n",
        "def gradientBoosting(X_train,y_train,X_test):\n",
        "    params = {'n_estimators': 800, 'max_depth': 8, 'min_samples_split': 2,\n",
        "          'learning_rate': 0.01, 'loss': 'ls'}\n",
        "    clf = GradientBoostingRegressor(**params)\n",
        "    clf.fit(X_train,y_train)\n",
        "    Y_test = clf.predict(X_test)\n",
        "    return Y_test\n",
        "X_train = preprocessing.scale(X_train)\n",
        "X_test = preprocessing.scale(X_test)\n",
        "y_test = gradientBoosting(X_train,y_train,X_test)\n",
        "for i in range(len(names_test)):\n",
        "    print(names_test[i],end='')\n",
        "    if(y_test[i]==1):\n",
        "        print(' +1')\n",
        "    else:\n",
        "        print(' -1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkoZYYPqvWXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.model_selection import KFold, cross_val_predict,GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "N, num_para = map(int,input().strip().split())\n",
        "X_train,y_train = [],[]\n",
        "for i in range(N):\n",
        "    ll = input().strip().split()\n",
        "    y_train.append(int(ll[1]))\n",
        "    ll = ll[2:]\n",
        "    for j in range(len(ll)):\n",
        "        ll[j] = float(ll[j].split(':')[1])\n",
        "    X_train.append(ll)\n",
        "\n",
        "num_test = int(input())\n",
        "X_test,names_test  = [],[]\n",
        "for i in range(num_test):\n",
        "    ll = input().strip().split()\n",
        "    names_test.append(ll[0])\n",
        "    ll = ll[1:]\n",
        "    for j in range(len(ll)):\n",
        "        ll[j] = float(ll[j].split(':')[1])\n",
        "    X_test.append(ll)\n",
        "\n",
        "\n",
        "estimator = Pipeline([(\"scaler\", StandardScaler()),\n",
        "        (\"polynomial_features\", PolynomialFeatures()),\n",
        "        (\"ridge_regression\", Ridge())])\n",
        "\n",
        "params = {\n",
        "    'polynomial_features__degree': [1, 2, 3],\n",
        "    'ridge_regression__alpha': np.geomspace(4, 20, 5)\n",
        "}\n",
        "#The KFold tells the cross validation object how to split up the data:\n",
        "kf = KFold(shuffle=True, random_state=72018, n_splits=3)\n",
        "#do hyper-parameter tuning\n",
        "grid = GridSearchCV(estimator, params, cv=kf)\n",
        "grid.fit(X_train, y_train)\n",
        "# print(grid.best_score_)\n",
        "# print(grid.best_params_)\n",
        "# print(r2_score(y_train, grid.predict(X_train)))\n",
        "# Notice that \"grid\" is a fit object!\n",
        "# We can use grid.predict(X_test) to get brand new predictions!\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "for i in range(len(names_test)):\n",
        "    print(names_test[i],end='')\n",
        "    if(y_pred[i]==1):\n",
        "        print(' +1')\n",
        "    else:\n",
        "        print(' -1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3XPejhsWziX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = int(input())\n",
        "for i in range(n):\n",
        "    a, b = input().strip().split(' ')\n",
        "    print (int(a) + int(b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEYxbTCPSMIr",
        "colab_type": "text"
      },
      "source": [
        "[Document Classification](https://www.hackerrank.com/challenges/document-classification/problem)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRoNIgMuSMr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "x_train=[] \n",
        "y_train=[]\n",
        "with open('trainingdata.txt') as f: \n",
        "    l = f.readline() \n",
        "    for line in f: \n",
        "        temp = line.split() \n",
        "        n=len(temp) \n",
        "        y_train.append(int(temp[0])) #contains category of each text\n",
        "        x_train.append( \" \".join(temp[1:n]) ) \n",
        "\n",
        "\n",
        "\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                    ('clf', SGDClassifier(loss='hinge', penalty='l2', \n",
        "                    alpha=1e-3, random_state=42,\n",
        "                    max_iter=5, tol=None))])\n",
        "# text_clf = Pipeline([('vect', TfidfVectorizer(ngram_range=(1,1), lowercase = False,\n",
        "#                min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
        "#                smooth_idf=1, sublinear_tf=1 )),\n",
        "#                     ('clf', LogisticRegression(class_weight='balanced', C=100))])\n",
        "\n",
        "text_clf = text_clf.fit(x_train,y_train)\n",
        "\n",
        "T = int(input())\n",
        "x_test=[]\n",
        "for data in range(T): \n",
        "    temp = str(input()) \n",
        "    x_test.append(temp)\n",
        "\n",
        "output=text_clf.predict(x_test)\n",
        "for i in range(T): \n",
        "    print(output[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tH-ljQ8VJ3v",
        "colab_type": "text"
      },
      "source": [
        "[Predict the Missing Grade](https://www.hackerrank.com/challenges/predict-missing-grade/problem)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vBZbjFDVKss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "num_lines = int(input())\n",
        "inputs = [json.loads(input()) for _ in range(num_lines)]\n",
        "test_df = pd.DataFrame(inputs).fillna(0)\n",
        "X_test = test_df.drop('serial',axis=1)\n",
        "#print(test_df.columns)\n",
        "\n",
        "# Getting training data\n",
        "with open('training.json') as f:\n",
        "    data = [json.loads(line) for line in f]\n",
        "    data.remove(data[0])\n",
        "    train_df = pd.DataFrame(data).fillna(0)\n",
        "#print(train_df.head())\n",
        "y_train = train_df['Mathematics']\n",
        "X_train = train_df.drop(['Mathematics','serial'],axis = 1)\n",
        "#print(X_train)\n",
        "\n",
        "\n",
        "# Declare model and fit\n",
        "clf = SGDClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "results = clf.predict(X_test)\n",
        "for res in results:\n",
        "    print(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkFq-e7dgSab",
        "colab_type": "text"
      },
      "source": [
        "[Missing Stock Prices](https://www.hackerrank.com/challenges/missing-stock-prices/problem)\n",
        "\n",
        "Approach\n",
        "\n",
        "The data provided here is of the format .\n",
        "The first line contains the number of rows followed by rows containing date, time and the highest price of the stock on that day.\n",
        "But if we observe the data carefully, we do not need the date and time for training an interpolation model as there is only one price value for each trading day.\n",
        "\n",
        "\n",
        "Interpolation works perfect for predicting values in between existing values.\n",
        "On the other hand, Extrapolation is used for data points outside of a given dataset. For instance, here, stock prices for tomorrow.  simply means using spline interpolation for one-dimensional data points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7siTZHMgS_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy import interpolate\n",
        "\n",
        "n = int(input())\n",
        "prices = []\n",
        "for i in range(n):\n",
        "    time, price = input().split(\"\\t\")\n",
        "    prices.append(price)\n",
        "\n",
        "#After the data has been collected we need to seperate the prices value \n",
        "#which are known from the ones which are missing using  and  respectively.\n",
        "x_known = []\n",
        "prices_float = []\n",
        "x_unknown = []\n",
        "\n",
        "for i in range(n):\n",
        "    if not \"Missing\" in prices[i]:\n",
        "        x_known.append(i)\n",
        "        prices_float.append(float(prices[i]))\n",
        "    else:\n",
        "        x_unknown.append(i)\n",
        "\n",
        "Y = np.array(prices_float)\n",
        "f = interpolate.UnivariateSpline(x_known, Y, s=1)\n",
        "\n",
        "for i in x_unknown:\n",
        "    print(f(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR5W8QfX5rz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Enter your code here. Read input from STDIN. Print output to STDOUT\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.model_selection import KFold, cross_val_predict,GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "n = int(input())\n",
        "df1 = []\n",
        "# build the dataframe\n",
        "for i in range(n):\n",
        "    df = input().strip().split('\\t')\n",
        "    df1.append([str(c) for c in df])\n",
        "\n",
        "df1 = pd.DataFrame(df1, columns=['Date','Price'])\n",
        "df1['Date'] = pd.to_datetime(df1['Date'])\n",
        "#print(df1.head(3))\n",
        "#create two dataframes - missing price dataframe and drop missing dataframe\n",
        "miss_df = df1[df1.Price.str.contains('Missing')]\n",
        "miss_df = miss_df.loc[:,miss_df.columns != 'Price']\n",
        "#print(miss_df.head(3))\n",
        "\n",
        "train_df = df1[~df1.Price.str.contains('Missing')]\n",
        "#print(train_df.head(3))\n",
        "\n",
        "estimator = Pipeline([\n",
        "        (\"polynomial_features\", PolynomialFeatures()),\n",
        "        (\"ridge_regression\", Ridge())])\n",
        "\n",
        "params = {\n",
        "    'polynomial_features__degree': [1, 2, 3],\n",
        "    'ridge_regression__alpha': np.geomspace(4, 20, 5)\n",
        "}\n",
        "#The KFold tells the cross validation object how to split up the data:\n",
        "kf = KFold(shuffle=True, random_state=72018, n_splits=3)\n",
        "#do hyper-parameter tuning\n",
        "grid = GridSearchCV(estimator, params, cv=kf)\n",
        "grid.fit(train_df.drop('Price',axis = 1), train_df['Price'])\n",
        "\n",
        "y_pred = grid.predict(miss_df)\n",
        "\n",
        "for i in y_pred:\n",
        "    print(i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTkFq5MJ-zGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_missing(prices):\n",
        "    missing_prices = []\n",
        "    \n",
        "    for i, price in enumerate(prices):\n",
        "        if price is None:\n",
        "            previous_adjacent = 0\n",
        "            weight_previous = 1\n",
        "            next_adjacent = 0\n",
        "            weight_next = 1\n",
        "            j = i\n",
        "            while previous_adjacent == 0:\n",
        "                j -= 1\n",
        "                if j < 0:\n",
        "                    break\n",
        "                if prices[j] is not None: \n",
        "                    previous_adjacent = prices[j]\n",
        "                else:\n",
        "                    weight_next +=1\n",
        "            j = i\n",
        "            while next_adjacent == 0:\n",
        "                j += 1\n",
        "                if j >= len(prices):\n",
        "                    break\n",
        "                if prices[j] is not None: \n",
        "                    next_adjacent = prices[j]       \n",
        "                else:\n",
        "                    weight_previous +=1\n",
        "            avg_adjacent = (previous_adjacent * weight_previous  + weight_next * next_adjacent) / (weight_previous + weight_next) if (previous_adjacent and next_adjacent) else previous_adjacent or next_adjacent\n",
        "            missing_prices.append(avg_adjacent)\n",
        "    \n",
        "    return missing_prices\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    num_lines = int(input().strip())\n",
        "    prices = []\n",
        "    for i in range(num_lines):\n",
        "        date, time, price = input().strip().split()\n",
        "        try:\n",
        "            price = float(price)\n",
        "        except ValueError:\n",
        "            price = None\n",
        "        prices.append(price)\n",
        "    missing_prices = calculate_missing(prices)\n",
        "    for price in missing_prices:\n",
        "        print(price)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}